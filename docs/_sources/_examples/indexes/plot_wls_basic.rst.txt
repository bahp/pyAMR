
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "_examples/indexes/plot_wls_basic.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download__examples_indexes_plot_wls_basic.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr__examples_indexes_plot_wls_basic.py:


SART - through WLS
------------------

.. todo: Explain

.. note: The slope of the fitted straight line is what we denote
         as SART (Single Antibiotic Resistance Trend). Need to
         find the code that computes and plots the trends as
         in the PhD thesis.

.. GENERATED FROM PYTHON SOURCE LINES 14-127



.. image:: /_examples/indexes/images/sphx_glr_plot_wls_basic_001.png
    :alt: plot wls basic
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /Users/cbit/Desktop/repositories/environments/venv-py37-pyamr/lib/python3.7/site-packages/statsmodels/regression/linear_model.py:764: RuntimeWarning: divide by zero encountered in log
      llf += 0.5 * np.sum(np.log(self.weights))

    Series:
    wls-rsquared                  0.5517
    wls-rsquared_adj              0.5471
    wls-fvalue                  120.6106
    wls-fprob                        0.0
    wls-aic                          inf
    wls-bic                          inf
    wls-llf                         -inf
    wls-mse_model            205108.7258
    wls-mse_resid              1700.5857
    wls-mse_total              3755.2133
    wls-const_coef              250.6076
    wls-const_std                17.6694
    wls-const_tvalue             14.1831
    wls-const_tprob                  0.0
    wls-const_cil               215.5432
    wls-const_ciu               285.6721
    wls-x1_coef                   2.7584
    wls-x1_std                    0.2512
    wls-x1_tvalue                10.9823
    wls-x1_tprob                     0.0
    wls-x1_cil                    2.2599
    wls-x1_ciu                    3.2568
    wls-s_dw               Jarque-Ber...
    wls-s_jb_value             Prob(JB):
    wls-s_jb_prob              Cond. No.
    wls-s_skew                 Kurtosis:
    wls-s_kurtosis                      
    wls-s_omnibus_value    Prob(Omnib...
    wls-s_omnibus_prob             Skew:
    wls-m_dw                      0.1608
    wls-m_jb_value                3.4524
    wls-m_jb_prob                  0.178
    wls-m_skew                   -0.4328
    wls-m_kurtosis                3.2819
    wls-m_nm_value                4.0698
    wls-m_nm_prob                 0.1307
    wls-m_ks_value                0.6087
    wls-m_ks_prob                    0.0
    wls-m_shp_value               0.9459
    wls-m_shp_prob                0.0004
    wls-m_ad_value                2.4996
    wls-m_ad_nnorm                 False
    wls-missing                    raise
    wls-exog               [[1.0, 0.0...
    wls-endog              [50.594521...
    wls-trend                          c
    wls-weights            [0.0593242...
    wls-W                  <pyamr.met...
    wls-model              <statsmode...
    wls-id                 WLS(c,Sig(...
    dtype: object

    Regression line:
    [250.61 253.37 256.12 258.88 261.64 264.4  267.16 269.92 272.67 275.43]

    Summary:
                                WLS Regression Results                            
    ==============================================================================
    Dep. Variable:                      y   R-squared:                       0.552
    Model:                            WLS   Adj. R-squared:                  0.547
    Method:                 Least Squares   F-statistic:                     120.6
    Date:                Tue, 30 Mar 2021   Prob (F-statistic):           9.06e-19
    Time:                        14:35:02   Log-Likelihood:                   -inf
    No. Observations:                 100   AIC:                               inf
    Df Residuals:                      98   BIC:                               inf
    Df Model:                           1                                         
    Covariance Type:            nonrobust                                         
    ==============================================================================
                     coef    std err          t      P>|t|      [0.025      0.975]
    ------------------------------------------------------------------------------
    const        250.6076     17.669     14.183      0.000     215.543     285.672
    x1             2.7584      0.251     10.982      0.000       2.260       3.257
    ==============================================================================
    Omnibus:                       11.497   Durbin-Watson:                   0.502
    Prob(Omnibus):                  0.003   Jarque-Bera (JB):               13.534
    Skew:                           0.634   Prob(JB):                      0.00115
    Kurtosis:                       4.281   Cond. No.                         217.
    Normal (N):                     4.070   Prob(N):                         0.131
    ==============================================================================






|

.. code-block:: default
   :lineno-start: 14

    # Import class.
    import sys
    import numpy as np
    import pandas as pd
    import matplotlib as mpl
    import matplotlib.pyplot as plt
    import statsmodels.api as sm
    import statsmodels.robust.norms as norms

    # import weights.
    from pyamr.datasets.load import make_timeseries
    from pyamr.core.regression.wls import WLSWrapper
    from pyamr.metrics.weights import SigmoidA

    # ----------------------------
    # set basic configuration
    # ----------------------------
    # Matplotlib options
    mpl.rc('legend', fontsize=6)
    mpl.rc('xtick', labelsize=6)
    mpl.rc('ytick', labelsize=6)

    # Set pandas configuration.
    pd.set_option('display.max_colwidth', 14)
    pd.set_option('display.width', 150)
    pd.set_option('display.precision', 4)

    # ----------------------------
    # create data
    # ----------------------------
    # Create timeseries data
    x, y, f = make_timeseries()

    # Create method to compute weights from frequencies
    W = SigmoidA(r=200, g=0.5, offset=0.0, scale=1.0)

    # Note that the function fit will call M.weights(weights) inside and will
    # store the M converter in the instance. Therefore, the code executed is
    # equivalent to <weights=M.weights(f)> with the only difference being that
    # the weight converter is not saved.
    wls = WLSWrapper(estimator=sm.WLS).fit( \
        exog=x, endog=y, trend='c', weights=f,
        W=W, missing='raise')

    # Print series.
    print("\nSeries:")
    print(wls.as_series())

    # Print regression line.
    print("\nRegression line:")
    print(wls.line(np.arange(10)))

    # Print summary.
    print("\nSummary:")
    print(wls.as_summary())

    # -----------------
    # Save & Load
    # -----------------
    # File location
    #fname = '../../examples/saved/wls-sample.pickle'

    # Save
    #wls.save(fname=fname)

    # Load
    #wls = WLSWrapper().load(fname=fname)

    # -------------
    #  Example I
    # -------------
    # This example shows how to make predictions using the wrapper and how
    # to plot the resultin data. In addition, it compares the intervales
    # provided by get_prediction (confidence intervals) and the intervals
    # provided by wls_prediction_std (prediction intervals). 
    #
    # To Do: Implement methods to compute CI and PI (see regression).

    # Variables.
    start, end = None, 180

    # Compute predictions (exogenous?). It returns a 2D array
    # where the rows contain the time (t), the mean, the lower
    # and upper confidence (or prediction?) interval.
    preds = wls.get_prediction(start=start, end=end)


    # Create figure
    fig, ax = plt.subplots(1, 1, figsize=(11,5))

    # Plotting confidence intervals
    # -----------------------------
    # Plot truth values.
    ax.plot(x, y, color='#A6CEE3', alpha=0.5, marker='o',
                  markeredgecolor='k', markeredgewidth=0.5,
                  markersize=5, linewidth=0.75, label='Observed')

    # Plot forecasted values.
    ax.plot(preds[0,:], preds[1, :], color='#FF0000', alpha=1.00,
                    linewidth=2.0, label=wls._identifier(short=True))

    # Plot the confidence intervals.
    ax.fill_between(preds[0, :], preds[2, :],
                                 preds[3, :],
                                 color='r',
                                 alpha=0.1)

    # Legend
    plt.legend()

    # Show
    plt.show()



.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.160 seconds)


.. _sphx_glr_download__examples_indexes_plot_wls_basic.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_wls_basic.py <plot_wls_basic.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_wls_basic.ipynb <plot_wls_basic.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
