
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "_examples\indexes\plot_sart_a_basic.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download__examples_indexes_plot_sart_a_basic.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr__examples_indexes_plot_sart_a_basic.py:


``SART`` - Trend as slope of ``WLS``
------------------------------------

.. todo: Explain

.. note: The slope of the fitted straight line is what we denote
         as SART (Single Antibiotic Resistance Trend). Need to
         find the code that computes and plots the trends as
         in the PhD thesis.

.. GENERATED FROM PYTHON SOURCE LINES 14-127



.. image-sg:: /_examples/indexes/images/sphx_glr_plot_sart_a_basic_001.png
   :alt: plot sart a basic
   :srcset: /_examples/indexes/images/sphx_glr_plot_sart_a_basic_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    c:\users\kelda\desktop\repositories\virtualenvs\venv-py391-pyamr\lib\site-packages\statsmodels\regression\linear_model.py:807: RuntimeWarning:

    divide by zero encountered in log


    Series:
    wls-rsquared                  0.5402
    wls-rsquared_adj              0.5355
    wls-fvalue                  115.1527
    wls-fprob                        0.0
    wls-aic                          inf
    wls-bic                          inf
    wls-llf                         -inf
    wls-mse_model            165533.2802
    wls-mse_resid              1437.5111
    wls-mse_total              3095.0441
    wls-const_coef               263.575
    wls-const_std                17.4154
    wls-const_tvalue             15.1346
    wls-const_tprob                  0.0
    wls-const_cil               229.0148
    wls-const_ciu               298.1352
    wls-x1_coef                   2.5975
    wls-x1_std                    0.2421
    wls-x1_tvalue                10.7309
    wls-x1_tprob                     0.0
    wls-x1_cil                    2.1171
    wls-x1_ciu                    3.0778
    wls-s_dw                       0.546
    wls-s_jb_value                14.895
    wls-s_jb_prob                 0.0006
    wls-s_skew                     0.697
    wls-s_kurtosis                 4.278
    wls-s_omnibus_value           12.662
    wls-s_omnibus_prob             0.002
    wls-m_dw                      0.1707
    wls-m_jb_value                4.7339
    wls-m_jb_prob                 0.0938
    wls-m_skew                   -0.5009
    wls-m_kurtosis                 3.364
    wls-m_nm_value                5.3656
    wls-m_nm_prob                 0.0684
    wls-m_ks_value                0.5809
    wls-m_ks_prob                    0.0
    wls-m_shp_value               0.9455
    wls-m_shp_prob                0.0004
    wls-m_ad_value                2.4183
    wls-m_ad_nnorm                 False
    wls-missing                    raise
    wls-exog               [[1.0, 0.0...
    wls-endog              [38.780154...
    wls-trend                          c
    wls-weights            [0.0328805...
    wls-W                  <pyamr.met...
    wls-model              <statsmode...
    wls-id                 WLS(c,Sig(...
    dtype: object

    Regression line:
    [263.58 266.17 268.77 271.37 273.96 276.56 279.16 281.76 284.35 286.95]

    Summary:
                                WLS Regression Results                            
    ==============================================================================
    Dep. Variable:                      y   R-squared:                       0.540
    Model:                            WLS   Adj. R-squared:                  0.536
    Method:                 Least Squares   F-statistic:                     115.2
    Date:                Thu, 15 Jun 2023   Prob (F-statistic):           3.16e-18
    Time:                        18:17:11   Log-Likelihood:                   -inf
    No. Observations:                 100   AIC:                               inf
    Df Residuals:                      98   BIC:                               inf
    Df Model:                           1                                         
    Covariance Type:            nonrobust                                         
    ==============================================================================
                     coef    std err          t      P>|t|      [0.025      0.975]
    ------------------------------------------------------------------------------
    const        263.5750     17.415     15.135      0.000     229.015     298.135
    x1             2.5975      0.242     10.731      0.000       2.117       3.078
    ==============================================================================
    Omnibus:                       12.662   Durbin-Watson:                   0.546
    Prob(Omnibus):                  0.002   Jarque-Bera (JB):               14.895
    Skew:                           0.697   Prob(JB):                     0.000583
    Kurtosis:                       4.278   Cond. No.                         231.
    Normal (N):                     5.366   Prob(N):                         0.068
    ==============================================================================






|

.. code-block:: default
   :lineno-start: 14

    # Import class.
    import sys
    import numpy as np
    import pandas as pd
    import matplotlib as mpl
    import matplotlib.pyplot as plt
    import statsmodels.api as sm
    import statsmodels.robust.norms as norms

    # import weights.
    from pyamr.datasets.load import make_timeseries
    from pyamr.core.regression.wls import WLSWrapper
    from pyamr.metrics.weights import SigmoidA

    # ----------------------------
    # set basic configuration
    # ----------------------------
    # Matplotlib options
    mpl.rc('legend', fontsize=6)
    mpl.rc('xtick', labelsize=6)
    mpl.rc('ytick', labelsize=6)

    # Set pandas configuration.
    pd.set_option('display.max_colwidth', 14)
    pd.set_option('display.width', 150)
    pd.set_option('display.precision', 4)

    # ----------------------------
    # create data
    # ----------------------------
    # Create timeseries data
    x, y, f = make_timeseries()

    # Create method to compute weights from frequencies
    W = SigmoidA(r=200, g=0.5, offset=0.0, scale=1.0)

    # Note that the function fit will call M.weights(weights) inside and will
    # store the M converter in the instance. Therefore, the code executed is
    # equivalent to <weights=M.weights(f)> with the only difference being that
    # the weight converter is not saved.
    wls = WLSWrapper(estimator=sm.WLS).fit( \
        exog=x, endog=y, trend='c', weights=f,
        W=W, missing='raise')

    # Print series.
    print("\nSeries:")
    print(wls.as_series())

    # Print regression line.
    print("\nRegression line:")
    print(wls.line(np.arange(10)))

    # Print summary.
    print("\nSummary:")
    print(wls.as_summary())

    # -----------------
    # Save & Load
    # -----------------
    # File location
    #fname = '../../examples/saved/wls-sample.pickle'

    # Save
    #wls.save(fname=fname)

    # Load
    #wls = WLSWrapper().load(fname=fname)

    # -------------
    #  Example I
    # -------------
    # This example shows how to make predictions using the wrapper and how
    # to plot the resultin data. In addition, it compares the intervales
    # provided by get_prediction (confidence intervals) and the intervals
    # provided by wls_prediction_std (prediction intervals). 
    #
    # To Do: Implement methods to compute CI and PI (see regression).

    # Variables.
    start, end = None, 180

    # Compute predictions (exogenous?). It returns a 2D array
    # where the rows contain the time (t), the mean, the lower
    # and upper confidence (or prediction?) interval.
    preds = wls.get_prediction(start=start, end=end)


    # Create figure
    fig, ax = plt.subplots(1, 1, figsize=(11,5))

    # Plotting confidence intervals
    # -----------------------------
    # Plot truth values.
    ax.plot(x, y, color='#A6CEE3', alpha=0.5, marker='o',
                  markeredgecolor='k', markeredgewidth=0.5,
                  markersize=5, linewidth=0.75, label='Observed')

    # Plot forecasted values.
    ax.plot(preds[0,:], preds[1, :], color='#FF0000', alpha=1.00,
                    linewidth=2.0, label=wls._identifier(short=True))

    # Plot the confidence intervals.
    ax.fill_between(preds[0, :], preds[2, :],
                                 preds[3, :],
                                 color='r',
                                 alpha=0.1)

    # Legend
    plt.legend()

    # Show
    plt.show()



.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.108 seconds)


.. _sphx_glr_download__examples_indexes_plot_sart_a_basic.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_sart_a_basic.py <plot_sart_a_basic.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_sart_a_basic.ipynb <plot_sart_a_basic.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
