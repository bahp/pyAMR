
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "_examples/forecasting/plot_wls_search.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download__examples_forecasting_plot_wls_search.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr__examples_forecasting_plot_wls_search.py:


WLS search
----------

.. note: Explain

.. GENERATED FROM PYTHON SOURCE LINES 8-142



.. image:: /_examples/forecasting/images/sphx_glr_plot_wls_search_001.png
    :alt: plot wls search
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /Users/cbit/Desktop/repositories/environments/venv-py37-pyamr/lib/python3.7/site-packages/statsmodels/regression/linear_model.py:764: RuntimeWarning: divide by zero encountered in log
      llf += 0.5 * np.sum(np.log(self.weights))
    /Users/cbit/Desktop/repositories/environments/venv-py37-pyamr/lib/python3.7/site-packages/statsmodels/regression/linear_model.py:764: RuntimeWarning: divide by zero encountered in log
      llf += 0.5 * np.sum(np.log(self.weights))
    /Users/cbit/Desktop/repositories/environments/venv-py37-pyamr/lib/python3.7/site-packages/statsmodels/regression/linear_model.py:764: RuntimeWarning: divide by zero encountered in log
      llf += 0.5 * np.sum(np.log(self.weights))
    /Users/cbit/Desktop/repositories/environments/venv-py37-pyamr/lib/python3.7/site-packages/statsmodels/regression/linear_model.py:764: RuntimeWarning: divide by zero encountered in log
      llf += 0.5 * np.sum(np.log(self.weights))
    /Users/cbit/Desktop/repositories/environments/venv-py37-pyamr/lib/python3.7/site-packages/statsmodels/regression/linear_model.py:764: RuntimeWarning: divide by zero encountered in log
      llf += 0.5 * np.sum(np.log(self.weights))

    Grid search:
                                0              1              2              3              4              5
    wls-rsquared            0.751         0.5441         0.5117         0.4565         0.4736          0.306
    wls-rsquare...         0.7485         0.5395         0.5067          0.451         0.4683         0.2989
    wls-fvalue           295.6206       116.9791       102.7083        82.3237        88.1785        43.2042
    wls-fprob                 0.0            0.0            0.0            0.0            0.0            0.0
    wls-aic             1125.5233            inf            inf            inf            inf            inf
    wls-bic             1130.7336            inf            inf            inf            inf            inf
    wls-llf             -560.7616           -inf           -inf           -inf           -inf           -inf
    wls-mse_model    1311438.7551    151807.5117    121157.3981     82671.0383     78042.1073     20038.4372
    wls-mse_resid        4436.222      1297.7321      1179.6266      1004.2195        885.047        463.808
    wls-mse_total      17638.2678      2818.0329      2391.5233      1829.1368      1664.4112       661.5315
    wls-const_coef       169.1865       265.8607       279.9291       303.8209       298.5518       379.3692
    wls-const_std         13.2217        16.6817        16.6347        16.2584        16.3377        11.5572
    wls-const_t...        12.7961        15.9373         16.828         18.687        18.2738        32.8254
    wls-const_t...            0.0            0.0            0.0            0.0            0.0            0.0
    wls-const_cil        142.9484       232.7564        246.918       271.5566       266.1301       356.4344
    wls-const_ciu        195.4245        298.965       312.9402       336.0853       330.9735       402.3041
    wls-x1_coef            3.9672         2.5147          2.329         2.0179         2.0747         1.0416
    wls-x1_std             0.2307         0.2325         0.2298         0.2224         0.2209         0.1585
    wls-x1_tvalue         17.1936        10.8157        10.1345         9.0732         9.3903          6.573
    wls-x1_tprob              0.0            0.0            0.0            0.0            0.0            0.0
    wls-x1_cil             3.5093         2.0533         1.8729         1.5765         1.6363         0.7271
    wls-x1_ciu             4.4251         2.9761          2.785         2.4592         2.5132          1.356
    wls-s_dw        Jarque-Ber...  Jarque-Ber...  Jarque-Ber...  Jarque-Ber...  Jarque-Ber...  Jarque-Ber...
    wls-s_jb_value      Prob(JB):      Prob(JB):      Prob(JB):      Prob(JB):      Prob(JB):      Prob(JB):
    wls-s_jb_prob       Cond. No.      Cond. No.      Cond. No.      Cond. No.      Cond. No.      Cond. No.
    wls-s_skew          Kurtosis:      Kurtosis:      Kurtosis:      Kurtosis:      Kurtosis:      Kurtosis:
    wls-s_kurtosis                                                                                          
    wls-s_omnib...  Prob(Omnib...  Prob(Omnib...  Prob(Omnib...  Prob(Omnib...  Prob(Omnib...  Prob(Omnib...
    wls-s_omnib...          Skew:          Skew:          Skew:          Skew:          Skew:          Skew:
    wls-m_dw               0.2554         0.1658         0.1494         0.1245         0.1297         0.0712
    wls-m_jb_value         4.0545         7.4044         9.8922         13.507         12.918        18.2404
    wls-m_jb_prob          0.1317         0.0247         0.0071         0.0012         0.0016         0.0001
    wls-m_skew              0.481        -0.6539        -0.7602        -0.8941        -0.8735        -1.0461
    wls-m_kurtosis         2.7814         3.2578         3.2505         3.2099         3.2195         2.9729
    wls-m_nm_value         4.0546         7.6675         9.6996        12.3503        11.9419        15.1598
    wls-m_nm_prob          0.1317         0.0216         0.0078         0.0021         0.0026         0.0005
    wls-m_ks_value         0.5283         0.5599         0.5699           0.59         0.5895         0.6547
    wls-m_ks_prob             0.0            0.0            0.0            0.0            0.0            0.0
    wls-m_shp_v...         0.9709         0.9443         0.9304         0.9074         0.9115         0.8559
    wls-m_shp_prob         0.0259         0.0004         0.0001            0.0            0.0            0.0
    wls-m_ad_value          0.947         2.3501         2.9833         4.0184          3.834         6.1731
    wls-m_ad_nnorm          False          False          False          False          False          False
    wls-exog        [[1.0, 0.0...  [[1.0, 0.0...  [[1.0, 0.0...  [[1.0, 0.0...  [[1.0, 0.0...  [[1.0, 0.0...
    wls-endog       [37.782704...  [37.782704...  [37.782704...  [37.782704...  [37.782704...  [37.782704...
    wls-trend                   c              c              c              c              c              c
    wls-weights     [1.0, 1.0,...  [0.1243128...  [0.0972866...  [0.0619735...  [0.0583873...  [9.7309002...
    wls-W           <statsmode...  <pyamr.met...  <pyamr.met...  <pyamr.met...  <pyamr.met...  <pyamr.met...
    wls-model       <statsmode...  <statsmode...  <statsmode...  <statsmode...  <statsmode...  <statsmode...
    wls-id          WLS(c,Leas...  WLS(c,Sig(...  WLS(c,Sig(...  WLS(c,Sig(...  WLS(c,Sig(...  WLS(c,Sig(...






|

.. code-block:: default
   :lineno-start: 8

    # Import class.
    import sys
    import numpy as np
    import pandas as pd
    import matplotlib as mpl
    import matplotlib.pyplot as plt
    import statsmodels.api as sm
    import statsmodels.robust.norms as norms

    # import weights.
    from pyamr.datasets.load import make_timeseries
    from pyamr.core.regression.wls import WLSWrapper
    from pyamr.metrics.weights import SigmoidA

    # ----------------------------
    # set basic configuration
    # ----------------------------
    # Matplotlib options
    mpl.rc('legend', fontsize=6)
    mpl.rc('xtick', labelsize=6)
    mpl.rc('ytick', labelsize=6)

    # Set pandas configuration.
    pd.set_option('display.max_colwidth', 14)
    pd.set_option('display.width', 150)
    pd.set_option('display.precision', 4)

    # ----------------------------
    # create data
    # ----------------------------
    # Create timeseries data
    x, y, f = make_timeseries()

    # -----------------------------
    # Example II
    # -----------------------------
    # This example performs grid search on a number of possible configurations
    # of the WLSWrapper. In particular, it tests the effect of different 
    # objects to compute the weights from the frequencies. It presents both
    # the resulting pandas dataframe and also a figure.

    # Configuration
    # -------------
    # This variable contains the weight functions to test. Note that in 
    # the norms module there are other options such as [norms.HuberT(), 
    # norms.Hampel(), norms.TrimmedMean(), norms.TukeyBiweight(), 
    # norms.AndreWave(), norms.RamsayE()]
    w_func = [
        norms.LeastSquares(),
        SigmoidA(r=200, g=0.5, offset=0.0, scale=1.0),
        SigmoidA(r=200, g=0.5, offset=0.0, scale=1.0, percentiles=[10, 90]),
        SigmoidA(r=200, g=0.5, offset=0.0, scale=1.0, percentiles=[25, 75]),
        SigmoidA(r=200, g=0.5, offset=0.0, scale=1.0, percentiles=[25, 90]),
        SigmoidA(r=200, g=0.5, offset=0.0, scale=1.0, percentiles=[40, 50])]

    # The grid search parameters.
    grid_params = [
        # {'exog': [x], 'endog': [y], 'trend': ['c']},
        {'exog': [x], 'endog': [y], 'trend': ['c'], 'weights': [f], 'W': w_func}
    ]

    # Grid search
    # ------------
    # Perform grid search.
    summary = WLSWrapper(estimator=sm.WLS) \
        .grid_search(grid_params=grid_params)

    # Show grid results
    # ..todo: It is weird to create an WLSWrapper jut to
    #         be able to use themethod from_list_dataframe.
    #         try to implemented separately.
    print("\nGrid search:")
    print(WLSWrapper().from_list_dataframe(summary).T)

    # Prediction
    # ----------
    # Variables.
    start, end = 10, 150

    # Create figure
    fig, axes = plt.subplots(1, 3, figsize=(10, 5))

    # Plot truth values.
    axes[0].plot(x, y, color='#A6CEE3', alpha=0.5, marker='o',
                 markeredgecolor='k', markeredgewidth=0.5,
                 markersize=5, linewidth=0.75, label='Observed')

    # Plot frequencies
    axes[0].bar(x, f, color='gray', alpha=0.7, label='Frequency')

    # For each of the models in summary
    for i, model in enumerate(summary):

        # Compute predictions.
        preds = model.get_prediction(start=start, end=end)

        # Plot forecasted values.
        axes[0].plot(preds[0, :], preds[1, :],
                     linewidth=1.0,
                     label=model._identifier(short=True))

        # Plot the confidence intervals.
        axes[0].fill_between(preds[0, :],
                             preds[2, :],
                             preds[3, :],
                             alpha=0.1)

        # Plot weights assigned to each observation
        axes[1].plot(model.weights, marker='o', alpha=0.5,
                     markeredgecolor='k', markeredgewidth=0.5,
                     markersize=4, linewidth=0.00,
                     label=model._identifier(short=True))

        # Plot weights converter (W) functions.
        if model.W is not None:
            axes[2].plot(np.linspace(0, 1, 100),
                         model.W.weights(np.linspace(0, 1, 100)),
                         label=model._identifier(short=True))

    # Grid.
    axes[0].grid(linestyle='--', linewidth=0.35, alpha=0.5)
    axes[1].grid(linestyle='--', linewidth=0.35, alpha=0.5)
    axes[2].grid(linestyle='--', linewidth=0.35, alpha=0.5)

    # Legend.
    axes[0].legend(loc=0)
    axes[1].legend(loc=0)
    axes[2].legend(loc=0)

    # Tight layout
    plt.tight_layout()

    # Show.
    plt.show()


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.646 seconds)


.. _sphx_glr_download__examples_forecasting_plot_wls_search.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_wls_search.py <plot_wls_search.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_wls_search.ipynb <plot_wls_search.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
