
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "_examples\forecasting\plot_wls_search.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download__examples_forecasting_plot_wls_search.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr__examples_forecasting_plot_wls_search.py:


WLS search
----------

.. note: Explain

.. GENERATED FROM PYTHON SOURCE LINES 8-142



.. image:: /_examples/forecasting/images/sphx_glr_plot_wls_search_001.png
    :alt: plot wls search
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    c:\users\kelda\desktop\repositories\virtualenvs\venvpy39-datablend\lib\site-packages\statsmodels\regression\linear_model.py:764: RuntimeWarning: divide by zero encountered in log
      llf += 0.5 * np.sum(np.log(self.weights))
    c:\users\kelda\desktop\repositories\virtualenvs\venvpy39-datablend\lib\site-packages\statsmodels\regression\linear_model.py:764: RuntimeWarning: divide by zero encountered in log
      llf += 0.5 * np.sum(np.log(self.weights))
    c:\users\kelda\desktop\repositories\virtualenvs\venvpy39-datablend\lib\site-packages\statsmodels\regression\linear_model.py:764: RuntimeWarning: divide by zero encountered in log
      llf += 0.5 * np.sum(np.log(self.weights))
    c:\users\kelda\desktop\repositories\virtualenvs\venvpy39-datablend\lib\site-packages\statsmodels\regression\linear_model.py:764: RuntimeWarning: divide by zero encountered in log
      llf += 0.5 * np.sum(np.log(self.weights))
    c:\users\kelda\desktop\repositories\virtualenvs\venvpy39-datablend\lib\site-packages\statsmodels\regression\linear_model.py:764: RuntimeWarning: divide by zero encountered in log
      llf += 0.5 * np.sum(np.log(self.weights))

    Grid search:
                                0              1              2              3              4              5
    wls-rsquared           0.7326         0.4695         0.4523         0.3664         0.3949           0.22
    wls-rsquare...         0.7298         0.4641         0.4467         0.3599         0.3887          0.212
    wls-fvalue           268.4341         86.728        80.9369        56.6616        63.9433        27.6396
    wls-fprob                 0.0            0.0            0.0            0.0            0.0            0.0
    wls-aic             1138.6735            inf            inf            inf            inf            inf
    wls-bic             1143.8839            inf            inf            inf            inf            inf
    wls-llf             -567.3368           -inf           -inf           -inf           -inf           -inf
    wls-mse_model    1358193.8031    105578.7956    102156.3186     54237.1796     51796.9868     15371.0175
    wls-mse_resid       5059.6925       1217.356      1262.1729       957.2127        810.045       556.1224
    wls-mse_total      18727.7138       2271.512      2281.3057      1495.3942      1325.0646       705.7678
    wls-const_coef       167.0527       294.0643       300.5184       337.2097       328.9345       391.8206
    wls-const_std         14.1203        16.7479        16.6647        15.5579        15.7332        12.5852
    wls-const_t...        11.8307        17.5583        18.0333        21.6745         20.907        31.1335
    wls-const_t...            0.0            0.0            0.0            0.0            0.0            0.0
    wls-const_cil        139.0315       260.8286       267.4479       306.3355       297.7125       366.8457
    wls-const_ciu        195.0739          327.3       333.5888       368.0838       360.1566       416.7955
    wls-x1_coef            4.0373         2.1809          2.101         1.6198         1.7144         0.9122
    wls-x1_std             0.2464         0.2342         0.2335         0.2152         0.2144         0.1735
    wls-x1_tvalue          16.384         9.3128         8.9965         7.5274         7.9965         5.2573
    wls-x1_tprob              0.0            0.0            0.0            0.0            0.0            0.0
    wls-x1_cil             3.5483         1.7162         1.6376         1.1927          1.289         0.5679
    wls-x1_ciu             4.5263         2.6456         2.5645         2.0468         2.1399         1.2566
    wls-s_dw        Jarque-Ber...  Jarque-Ber...  Jarque-Ber...  Jarque-Ber...  Jarque-Ber...  Jarque-Ber...
    wls-s_jb_value      Prob(JB):      Prob(JB):      Prob(JB):      Prob(JB):      Prob(JB):      Prob(JB):
    wls-s_jb_prob       Cond. No.      Cond. No.      Cond. No.      Cond. No.      Cond. No.      Cond. No.
    wls-s_skew          Kurtosis:      Kurtosis:      Kurtosis:      Kurtosis:      Kurtosis:      Kurtosis:
    wls-s_kurtosis                                                                                          
    wls-s_omnib...  Prob(Omnib...  Prob(Omnib...  Prob(Omnib...  Prob(Omnib...  Prob(Omnib...  Prob(Omnib...
    wls-s_omnib...          Skew:          Skew:          Skew:          Skew:          Skew:          Skew:
    wls-m_dw               0.1764         0.0972         0.0928         0.0715         0.0759         0.0494
    wls-m_jb_value          2.919         14.552        15.4572        19.2927        18.7571        20.6205
    wls-m_jb_prob          0.2324         0.0007         0.0004         0.0001         0.0001            0.0
    wls-m_skew             0.4125        -0.9034        -0.9344        -1.0605        -1.0431        -1.1095
    wls-m_kurtosis         2.8583         3.4777         3.4664         3.3623         3.3865         3.1589
    wls-m_nm_value         3.0124        13.4429        14.0647        16.4508         16.149        16.9249
    wls-m_nm_prob          0.2217         0.0012         0.0009         0.0003         0.0003         0.0002
    wls-m_ks_value          0.526         0.6121         0.6098           0.63         0.6296         0.6892
    wls-m_ks_prob             0.0            0.0            0.0            0.0            0.0            0.0
    wls-m_shp_v...         0.9766         0.9147         0.9097         0.8821         0.8871         0.8557
    wls-m_shp_prob         0.0715            0.0            0.0            0.0            0.0            0.0
    wls-m_ad_value         0.7845            3.6         3.8132          4.963         4.7582         5.9478
    wls-m_ad_nnorm          False          False          False          False          False          False
    wls-exog        [[1.0, 0.0...  [[1.0, 0.0...  [[1.0, 0.0...  [[1.0, 0.0...  [[1.0, 0.0...  [[1.0, 0.0...
    wls-endog       [20.358451...  [20.358451...  [20.358451...  [20.358451...  [20.358451...  [20.358451...
    wls-trend                   c              c              c              c              c              c
    wls-weights     [1.0, 1.0,...  [0.0076805...  [0.0067359...  [0.0020584...  [0.0024904...  [5.7199040...
    wls-W           <statsmode...  <pyamr.met...  <pyamr.met...  <pyamr.met...  <pyamr.met...  <pyamr.met...
    wls-model       <statsmode...  <statsmode...  <statsmode...  <statsmode...  <statsmode...  <statsmode...
    wls-id          WLS(c,Leas...  WLS(c,Sig(...  WLS(c,Sig(...  WLS(c,Sig(...  WLS(c,Sig(...  WLS(c,Sig(...






|

.. code-block:: default
   :lineno-start: 8

    # Import class.
    import sys
    import numpy as np
    import pandas as pd
    import matplotlib as mpl
    import matplotlib.pyplot as plt
    import statsmodels.api as sm
    import statsmodels.robust.norms as norms

    # import weights.
    from pyamr.datasets.load import make_timeseries
    from pyamr.core.regression.wls import WLSWrapper
    from pyamr.metrics.weights import SigmoidA

    # ----------------------------
    # set basic configuration
    # ----------------------------
    # Matplotlib options
    mpl.rc('legend', fontsize=6)
    mpl.rc('xtick', labelsize=6)
    mpl.rc('ytick', labelsize=6)

    # Set pandas configuration.
    pd.set_option('display.max_colwidth', 14)
    pd.set_option('display.width', 150)
    pd.set_option('display.precision', 4)

    # ----------------------------
    # create data
    # ----------------------------
    # Create timeseries data
    x, y, f = make_timeseries()

    # -----------------------------
    # Example II
    # -----------------------------
    # This example performs grid search on a number of possible configurations
    # of the WLSWrapper. In particular, it tests the effect of different 
    # objects to compute the weights from the frequencies. It presents both
    # the resulting pandas dataframe and also a figure.

    # Configuration
    # -------------
    # This variable contains the weight functions to test. Note that in 
    # the norms module there are other options such as [norms.HuberT(), 
    # norms.Hampel(), norms.TrimmedMean(), norms.TukeyBiweight(), 
    # norms.AndreWave(), norms.RamsayE()]
    w_func = [
        norms.LeastSquares(),
        SigmoidA(r=200, g=0.5, offset=0.0, scale=1.0),
        SigmoidA(r=200, g=0.5, offset=0.0, scale=1.0, percentiles=[10, 90]),
        SigmoidA(r=200, g=0.5, offset=0.0, scale=1.0, percentiles=[25, 75]),
        SigmoidA(r=200, g=0.5, offset=0.0, scale=1.0, percentiles=[25, 90]),
        SigmoidA(r=200, g=0.5, offset=0.0, scale=1.0, percentiles=[40, 50])]

    # The grid search parameters.
    grid_params = [
        # {'exog': [x], 'endog': [y], 'trend': ['c']},
        {'exog': [x], 'endog': [y], 'trend': ['c'], 'weights': [f], 'W': w_func}
    ]

    # Grid search
    # ------------
    # Perform grid search.
    summary = WLSWrapper(estimator=sm.WLS) \
        .grid_search(grid_params=grid_params)

    # Show grid results
    # ..todo: It is weird to create an WLSWrapper jut to
    #         be able to use themethod from_list_dataframe.
    #         try to implemented separately.
    print("\nGrid search:")
    print(WLSWrapper().from_list_dataframe(summary).T)

    # Prediction
    # ----------
    # Variables.
    start, end = 10, 150

    # Create figure
    fig, axes = plt.subplots(1, 3, figsize=(10, 5))

    # Plot truth values.
    axes[0].plot(x, y, color='#A6CEE3', alpha=0.5, marker='o',
                 markeredgecolor='k', markeredgewidth=0.5,
                 markersize=5, linewidth=0.75, label='Observed')

    # Plot frequencies
    axes[0].bar(x, f, color='gray', alpha=0.7, label='Frequency')

    # For each of the models in summary
    for i, model in enumerate(summary):

        # Compute predictions.
        preds = model.get_prediction(start=start, end=end)

        # Plot forecasted values.
        axes[0].plot(preds[0, :], preds[1, :],
                     linewidth=1.0,
                     label=model._identifier(short=True))

        # Plot the confidence intervals.
        axes[0].fill_between(preds[0, :],
                             preds[2, :],
                             preds[3, :],
                             alpha=0.1)

        # Plot weights assigned to each observation
        axes[1].plot(model.weights, marker='o', alpha=0.5,
                     markeredgecolor='k', markeredgewidth=0.5,
                     markersize=4, linewidth=0.00,
                     label=model._identifier(short=True))

        # Plot weights converter (W) functions.
        if model.W is not None:
            axes[2].plot(np.linspace(0, 1, 100),
                         model.W.weights(np.linspace(0, 1, 100)),
                         label=model._identifier(short=True))

    # Grid.
    axes[0].grid(linestyle='--', linewidth=0.35, alpha=0.5)
    axes[1].grid(linestyle='--', linewidth=0.35, alpha=0.5)
    axes[2].grid(linestyle='--', linewidth=0.35, alpha=0.5)

    # Legend.
    axes[0].legend(loc=0)
    axes[1].legend(loc=0)
    axes[2].legend(loc=0)

    # Tight layout
    plt.tight_layout()

    # Show.
    plt.show()


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.481 seconds)


.. _sphx_glr_download__examples_forecasting_plot_wls_search.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_wls_search.py <plot_wls_search.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_wls_search.ipynb <plot_wls_search.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
